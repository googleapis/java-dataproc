// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/dataproc/v1/shared.proto

package com.google.cloud.dataproc.v1;

public interface SparkHistoryServerConfigOrBuilder extends
    // @@protoc_insertion_point(interface_extends:google.cloud.dataproc.v1.SparkHistoryServerConfig)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <pre>
   * Optional. Resource name of an existing Dataproc Cluster to act as a Spark History
   * Server for the workload.
   * Example:
   * * `projects/[project_id]/regions/[region]/clusters/[cluster_name]`
   * </pre>
   *
   * <code>string dataproc_cluster = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
   * @return The dataprocCluster.
   */
  java.lang.String getDataprocCluster();
  /**
   * <pre>
   * Optional. Resource name of an existing Dataproc Cluster to act as a Spark History
   * Server for the workload.
   * Example:
   * * `projects/[project_id]/regions/[region]/clusters/[cluster_name]`
   * </pre>
   *
   * <code>string dataproc_cluster = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
   * @return The bytes for dataprocCluster.
   */
  com.google.protobuf.ByteString
      getDataprocClusterBytes();
}
